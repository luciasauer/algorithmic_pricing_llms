\section{Introduction}\label{sec:intro}

\epigraph{\en{A few years ago, two companies were selling a textbook called The Making of a Fly. One of those sellers used an algorithm which essentially matched its rival's price. That rival had an algorithm which always set a price 27\% higher than the first. The result was that prices kept spiralling upwards, until finally someone noticed what was going on, and adjusted the price manually. By that time, the book was selling – or rather, not selling – for 23 million dollars a copy.}}{Margrethe Vestager, \emph{European Commissioner}, ~\cite*{vestager_algorithms_2017}}

% \begin{displayquote}
%     \en{A few years ago, two companies were selling a textbook called The Making of a Fly. One of those sellers used an algorithm which essentially matched its rival's price. That rival had an algorithm which always set a price 27\% higher than the first. The result was that prices kept spiralling upwards, until finally someone noticed what was going on, and adjusted the price manually. By that time, the book was selling – or rather, not selling – for 23 million dollars a copy.}
%     \begin{flushright}
%         --- Margrethe Vestager, \emph{European Commissioner}, ~\cite*{vestager_algorithms_2017}
%     \end{flushright}
% \end{displayquote}

The dawn of artificial intelligence in pricing represents one of the most consequential shifts in market dynamics since the introduction of electronic trading. While Commissioner Vestager's anecdote illustrates the unintended consequences of simple algorithmic interactions, recent advances in LLMs suggest far more sophisticated possibilities. When AI systems capable of strategic reasoning and autonomous decision-making compete in markets, they demonstrate remarkable abilities to coordinate pricing without explicit agreements. Yet a fundamental question remains unanswered: do these AI coordination mechanisms follow the same theoretical boundaries that govern human collusion, or do they represent an entirely new category of competitive threat?

\subsection{Background and Motivation}
The rise of algorithmic pricing has fundamentally altered competitive dynamics across industries. From Amazon's dynamic pricing algorithms to airlines' revenue management systems, artificial intelligence increasingly determines the prices consumers pay for goods and services. This technological shift has attracted intense regulatory scrutiny, with competition authorities worldwide expressing concern about the potential of algorithms to facilitate tacit collusion without explicit agreements between firms \parencite{oecd_algorithmic_2023, harrington_developing_2018}. 

For instance, the \textcite{us_department_of_justice_price_2021} emphasizes that unlawful collusion typically requires some form of agreement or coordination among firms. Yet with algorithmic pricing, such coordination may emerge autonomously, complicating legal enforcement. These concerns are rooted not only in the implications for firm behavior, but in the broader consequences for social welfare: anticompetitive outcomes can lead to higher prices, reduced output, and diminished consumer surplus—hallmarks of inefficiency and welfare loss.

Recent research by \textcite{fish_algorithmic_2025} demonstrates that LLM based pricing agents autonomously achieve supracompetitive outcomes in duopoly settings, coordinating through sophisticated "price-war avoidance" mechanisms without explicit instructions to collude. Unlike traditional Q-learning algorithms that require extensive trial-and-error learning, LLM agents leverage pre-trained knowledge about strategic behavior to recognize and implement coordination strategies with unprecedented speed and effectiveness.


\subsection{Research Questions and Contributions}
However, \textcite{fish_algorithmic_2025}—virtually all algorithmic collusion studies—focuses exclusively on duopoly interactions. Economic theory provides clear predictions about what should happen as market competition intensifies: the \emph{Folk Theorem} establishes that collusion sustainability requires increasingly patient behavior as the number of competitors grows, with the critical condition $\delta \geq \frac{\pi^D - \pi^C}{\pi^D}$ becoming harder to satisfy when collusive profits $\pi^C = \frac{\pi^M}{n}$ must be shared among $n$ participants.

Whether LLM agents follow these same theoretical boundaries represents a critical gap with implications for competition policy. If AI coordination proves more robust than human collusion, markets with multiple algorithmic competitors may sustain harmful coordination, contrary to economic theory's predictions of competition. Conversely, if LLM agents face similar or more severe coordination constraints, policy interventions could focus on ensuring sufficient market participation rather than restricting algorithmic capabilities. Therefore, this thesis investigates a fundamental question at the intersection of artificial intelligence, game theory, and competition policy:

\textbf{Primary Research Question:} Do LLM agent collusion mechanisms break down according to \emph{Folk Theorem} predictions as market concentration decreases, and if so, at what critical thresholds?

\textbf{Secondary Questions:}
\begin{itemize}
    \item How does collusion stability vary across $n = 2, 3, 4, 5+$ LLM agents in controlled oligopoly settings?
    \item What coordination mechanisms emerge, persist, or fail as strategic complexity increases with more participants?
    \item Do breakdown patterns align with theoretical predictions from the \emph{Folk Theorem} and empirical evidence from human experiments?
\end{itemize}

Our contributions span theoretical, empirical, and policy dimensions. Theoretically, we provide the first systematic test of \emph{Folk Theorem} predictions in LLM agent coordination, extending algorithmic collusion research beyond duopoly settings to examine breakdown boundaries. Empirically, we establish a controlled experimental framework for testing AI coordination across varying market structures, generating quantitative evidence on stability thresholds and coordination mechanisms. From a policy perspective, our findings inform competition authorities about the scope and limitations of AI coordination threats, providing evidence-based foundations for regulatory approaches to algorithmic pricing in concentrated markets.

This gap is particularly significant given the rapid advancement of LLM technology. Unlike traditional reinforcement learning algorithms, which require long training horizons to converge to stable pricing strategies through trial-and-error exploration—and are vulnerable to adversarial exploitation—LLMs sidestep both concerns. They arrive pre-trained on vast corpora of human-generated text about markets, competition, and strategic behavior, are considerably more robust to manipulation, and have a much lower barrier to entry, as demonstrated by their rapid adoption. As \textcite{fish_algorithmic_2025} demonstrate, this enables LLM agents to recognize and implement sophisticated coordination strategies with speed and effectiveness. Yet their analysis, like virtually all algorithmic collusion research, employs stylized economic environments that abstract away from the rich strategic landscape of real markets.

\subsection{Outline}

This thesis proceeds in five additional chapters. \chapterref{sec:litrev} provides a comprehensive literature review spanning algorithmic collusion theory, LLM agent capabilities, empirical coordination studies, and regulatory approaches to AI pricing. \chapterref{sec:meth} details our experimental methodology, and agent configuration protocols. \chapterref{sec:res} presents our core findings on LLM coordination capabilities and compares agent behavior to documented human coordination patterns. \chapterref{sec:dis} discusses robustness across different market conditions and agent configurations, while \chapterref{sec:con} concludes with policy implications and directions for future research.

% As AI systems become increasingly sophisticated and ubiquitous in competitive markets, understanding their strategic capabilities becomes essential for maintaining competitive market outcomes. Our findings will inform both the development of AI systems and the regulatory frameworks needed to govern their deployment in strategic business contexts.