\section{Literature Review}\label{sec:litrev}

%Our literature review synthesizes research across four interconnected domains to establish the theoretical and empirical foundation for investigating collusion among Large Language Model (LLM) agents in real-world market conditions. Building on the theoretical innovations of \textcite{fish_algorithmic_2025} and the empirical insights of \textcite{byrne_learning_2019}, this review demonstrates how algorithmic collusion research can be enhanced through integration with empirical market studies, particularly in gasoline retail markets where coordination mechanisms are well-documented and data is readily available. However, and as \textcite[p.24]{fish_algorithmic_2025} state:
%\begin{displayquote}
%    \en{[\dots] our economic environment is simple and does not capture many real-world complexities, and we focus on one fixed time horizon. We leave exploring these frontiers to future research.}
%\end{displayquote}
%
%Therefore, this synthesis addresses a critical gap: while theoretical studies demonstrate the capacity of LLM agents for autonomous collusion in controlled settings, and empirical studies reveal sophisticated coordination mechanisms in real markets, research so far has not yet combined these approaches to examine how LLM agents behave when exposed to actual market conditions and coordination patterns observed in empirical data.
%
%
%\subsection{Theoretical foundations of algorithmic collusion}
%
%The theoretical understanding of algorithmic collusion has evolved from early demonstrations of emergent coordination in simple learning algorithms to sophisticated analyses of Large Language Model agents capable of strategic reasoning. This evolution encompasses three critical phases that lay the groundwork for understanding how AI systems can autonomously develop and implement collaborative strategies. The progression begins with seminal contributions that proved algorithmic collusion was theoretically possible, advances through sophisticated analyses of modern AI approaches that reveal the mechanisms underlying algorithmic coordination, and culminates in empirical validation demonstrating that these theoretical possibilities manifest in actual market outcomes.
%
%\subsubsection*{Seminal contributions and core mechanisms}
%
%The theoretical foundation for algorithmic collusion was established by \textcite{calvano_artificial_2020} in their seminal \emph{American Economic Review} paper, which demonstrated that Q-learning algorithms can autonomously develop collusive strategies without explicit coordination. Using simulations of repeated Bertrand competition with logit demand, they found algorithms consistently reached supracompetitive prices sustained by sophisticated reward-punishment schemes featuring finite punishment phases followed by gradual returns to cooperation.
%
%This foundational work established three critical insights: first, that artificial intelligence can independently discover and implement classical collusive strategies; second, that no explicit communication or agreement is required for algorithmic coordination; and third, that these outcomes emerge from standard profit-maximization objectives rather than programmed collusive intent.
%
%\textcite{klein_autonomous_2021} extended this framework to sequential pricing environments using the Maskin-Tirole model, demonstrating that Q-learning algorithms converge to collusive equilibria when price sets are limited, and to supra-competitive asymmetric cycles when price flexibility increases. This work established the robustness of algorithmic collusion across different market structures and timing assumptions, while \textcite{calvano_algorithmic_2021} demonstrated that these results hold even under imperfect monitoring conditions, as adapted from \textcite{green_noncooperative_1984}.
%
%\subsubsection*{Advanced algorithmic approaches and emergent behaviors}
%
%Recent research has expanded beyond Q-learning to examine more sophisticated AI systems. 
%\textcite{calvano_algorithmic_2023} distinguished between \en{genuine} and \en{spurious} collusion, showing that algorithm design choices critically determine collusive outcomes, while \textcite{asker_artificial_2022, asker_impact_2024} analysis revealed that synchronous updating leads to competitive pricing, while asynchronous learning approaches result in monopolistic levels, highlighting how seemingly technical implementation decisions have profound competitive implications.
%
%The emergence of LLM agents represents a paradigm shift in algorithmic collusion research. \textcite{fish_algorithmic_2025} provided the first comprehensive analysis of Large Language Model pricing agents, revealing three critical findings: (1) Large Language Models (LLMs) demonstrate natural proficiency in pricing tasks, (2) autonomously reach supracompetitive prices in oligopoly settings, and (3) exhibit extreme sensitivity to prompt variations. Their off-path analysis revealed price-war avoidance as a key mechanism, while extensions to auction environments demonstrated the generalizability of LLM collusive behavior.
%
%This research is particularly significant because LLM agents operate through fundamentally different mechanisms than traditional reinforcement learning algorithms. Rather than learning through trial-and-error exploration, LLMs leverage pre-trained knowledge about markets, competition, and strategic behavior, enabling them to recognize and implement sophisticated coordination strategies more rapidly and with a better understanding of context.
%
%\subsubsection*{Empirical validation in real markets}
%
%The transition from theoretical possibility to empirical reality was confirmed by \textcite{assad_algorithmic_2024} in their study of German gasoline markets. Using structural break analysis to identify the adoption of algorithmic pricing, they found that algorithm deployment increased margins by 15\% in non-monopoly markets, with a 36\% increase when all firms in duopoly and triopoly markets adopted algorithmic pricing. Notably, markets with only partial adoption showed no significant margin changes, suggesting that coordination effects emerge only when all competitors use algorithms. Thus, this study provides the first concrete evidence that algorithmic pricing leads to supracompetitive outcomes in actual markets.
%
%Their methodology---using headquarters-level adoption decisions as instrumental variables---established a template for identifying algorithmic coordination in observational data. The German gasoline market setting is particularly valuable because it features high-frequency price changes, spatial competition, and documented coordination patterns that provide natural benchmarks for algorithmic behavior.
%
%\subsection{LLM agents and economic simulation advances}
%
%The integration of Large Language Models into economic simulation represents a paradigmatic shift from traditional agent-based modeling approaches, offering unprecedented capabilities for capturing sophisticated strategic behavior and economic reasoning. This advancement encompasses three interconnected developments that collectively demonstrate the superior potential of LLM agents for understanding market dynamics and strategic interaction. The transformation begins with methodological innovations that enable more realistic economic simulations, progresses through documented evidence of the emergence of spontaneous strategic behavior, and concludes with empirical demonstrations of LLM agents' advantages over conventional algorithmic approaches in capturing complex economic phenomena.
%
%\subsubsection*{Methodological innovations in agent-based modeling}
%
%The integration of LLMs into economic simulation represents a fundamental advancement in computational economics. \textcite{li_econagent_2024, li_large_2023} demonstrated LLM agents' superior performance in macroeconomic simulation through their EconAgent framework, which successfully reproduced key economic phenomena, including the Phillips curve and Okun's law---relationships that traditional rule-based and reinforcement learning approaches failed to capture accurately.
%
%The methodological innovation stems from the multi-module architecture of LLM agents, which combines perception, memory, reflection, and action capabilities. This enables agents to process complex economic information, maintain decision histories, adapt strategies based on experience, and generate realistic economic choices---capabilities that mirror human economic decision-making more closely than traditional algorithmic approaches.
%
%\textcite{gao_large_2024} provide a comprehensive survey of LLM-empowered agent-based modeling applications across cyber, physical, social, and hybrid domains. Their review demonstrates the versatility of LLM agents in simulating complex systems. It highlights the potential for these approaches to capture sophisticated social dynamics underlying economic decision-making, including information propagation and strategic interactions relevant to coordination and collusion.
%
%\subsubsection*{Strategic behavior and collusion emergence}
%
%Recent research reveals that LLM agents spontaneously develop sophisticated strategic behaviors. \textcite[p.1]{lin_strategic_2025} found that LLM agents can:
%    \begin{displayquote}
%        \en{effectively monopolize specific commodities by dynamically adjusting their pricing and resource allocation strategies, thereby maximizing profitability without direct human input or explicit collusion commands.}
%    \end{displayquote}
%In multi-commodity Cournot competition, the researchers observed that agents \en{effectively divide sales territories among each other and tacitly collude to discourage competition at the expense of the consumer} \parencite[p.2]{lin_strategic_2025}. Critically, \en{despite the absence of any explicit communication channel, agents never re-enter a market once they have exited} \parencite[p.6]{lin_strategic_2025} demonstrating \en{an implicit understanding of the long-term consequences} and suggesting \en{emergent collusive dynamics} \parencite[p.6]{lin_strategic_2025}.
%
%The implications for collusion research are profound. \textcite[p.8]{lin_strategic_2025} argue that \en{LLMs possess the reasoning capability to reach cooperative equilibria} and that this behavior is \en{particularly surprising given the absence of explicit coordination channels and the potential short-term profits available from market re-entry}. While traditional algorithms learn collusive strategies through iterative market interactions, LLM agents appear to demonstrate an inherent strategic understanding that enables the rapid recognition and implementation of coordination mechanisms. This represents a qualitative difference in how algorithmic collusion might emerge and persist in real markets.
%
%\subsubsection*{Comparative advantages over traditional approaches}
%
%Empirical validation demonstrates the superiority of LLM agents across multiple dimensions. Compared to rule-based agent-based models, LLM agents exhibit greater flexibility and adaptability to unforeseen circumstances. In comparison to reinforcement learning approaches, they demonstrate superior stability in macroeconomic indicators and better integration of domain-specific knowledge, without requiring extensive training periods.
%
%Most significantly for collusion research, LLM agents demonstrate a more sophisticated understanding of strategic interaction contexts. Traditional Q-learning algorithms discover collusive strategies through mechanical trial-and-error processes. At the same time, LLM agents appear to understand the strategic logic underlying coordination, enabling them to adapt collusive strategy to new market conditions and regulatory environments.
%
%\subsection{Empirical gasoline market coordination studies}
%
%The empirical literature on gasoline market coordination provides essential insights into how real-world coordination mechanisms emerge, persist, and adapt across different competitive environments, offering crucial benchmarks for evaluating algorithmic behavior in realistic market contexts. Gasoline markets represent an ideal empirical foundation for LLM agent simulation studies due to several distinctive characteristics: inelastic demand that makes coordination particularly profitable and stable, standardized homogeneous products that eliminate product differentiation complexities, high-frequency transparent pricing that generates rich datasets while facilitating coordination mechanisms, and well-documented spatial competition dynamics with clear market boundaries. This rich empirical foundation spans three complementary research streams that collectively illuminate the sophisticated strategies firms employ to achieve and maintain coordination without explicit agreements.
%
%\subsubsection*{Established coordination mechanisms and market dynamics}
%
%\textcite{byrne_learning_2019} documented a three-year transition to coordinated equilibrium in Western Australian gasoline markets, revealing how firms use price leadership and experimentation to create focal points and enhance margins. Their 15-year station-level analysis demonstrated that coordination emerges gradually through learning processes that soften competition.
%
%This research provides an ideal empirical foundation for LLM agent studies because it documents the specific mechanisms through which coordination develops: dominant firms establish price leadership, experimentation creates focal points for coordination, and gradual learning processes enable sustained coordination without explicit communication. These mechanisms are precisely the types of strategic behaviors that LLM agents appear capable of recognizing and implementing.
%
%\textcite{clark_effect_2014} provided complementary evidence through their natural experiment study of a Quebec gasoline cartel collapse. Their findings that margins fell 30\% in target markets and 15\% in cyclical markets, while asymmetric price adjustments became more symmetric, demonstrate the substantial welfare effects of coordination and the importance of strategic mechanisms in maintaining supracompetitive pricing.
%
%\subsubsection*{Advanced empirical methodologies for coordination detection}
%
%The literature on the gasoline market has developed approaches for detecting and measuring coordination that are directly applicable to algorithmic collusion research. \textcite{byrne_learning_2019} employed natural experiments with information-sharing regime changes to demonstrate that strategic ignorance can create price commitment mechanisms, resulting in higher price-cost margins. Their finding that asymmetric information sharing increases margins provides crucial insights into how algorithmic agents might use information strategically.
%
%Structural approaches to coordination analysis have been extensively developed. \textcite{houde_spatial_2012} combined Berry-Levinsohn-Pakes demand estimation with spatial competition models, specifying commuting paths as consumer "locations" in Hotelling-style models. This methodological innovation enables precise measurement of competition effects and market power---potentially providing benchmarks for evaluating algorithmic pricing outcomes.
%
%The literature has also identified diverse coordination mechanisms across different market contexts. Studies across the United States, Canada, Australia, and Germany have documented Edgeworth cycles, price leadership patterns, simultaneous price increases, and calendar synchronization of price changes. This rich empirical foundation provides natural benchmarks for evaluating whether LLM agents reproduce realistic coordination patterns when exposed to actual market conditions.
%
%\subsubsection*{Information sharing and technological coordination}
%
%Recent research has investigated the impact of technological changes on coordination mechanisms. As discussed earlier, \textcite{assad_algorithmic_2024} demonstrated that the adoption of algorithmic pricing creates new forms of coordination that differ qualitatively from traditional strategic interactions. Their finding that margins increased 36\% when all duopoly participants adopted algorithms suggests that technological coordination can be more effective than traditional mechanisms.
%
%The information-sharing literature provides crucial insights for understanding LLM agent behavior. Multiple studies demonstrate that transparency and information availability can facilitate rather than prevent coordination, with strategic ignorance sometimes enhancing rather than reducing collusive outcomes. This literature is particularly relevant for LLM agents, which process vast amounts of market information and may develop sophisticated strategies for using information asymmetries strategically \parencite{kuhn_information_1995, gal_algorithmic-facilitated_2017}.
%
%\subsection{Regulatory challenges and transparency effects}
%
%The emergence of algorithmic collusion poses unprecedented challenges for regulatory frameworks designed around traditional models of strategic coordination, necessitating fundamental reconsiderations of antitrust enforcement and competition policy in the digital economy. These challenges manifest across three interconnected dimensions that collectively reveal the inadequacy of existing regulatory approaches and the urgent need for innovative enforcement strategies. The regulatory landscape encompasses traditional antitrust frameworks struggling to address autonomous algorithmic coordination, emerging detection methodologies that leverage technological advances to identify collusive patterns, and evolving policy approaches that seek to balance innovation incentives with consumer protection in algorithmic markets \parencite{ezrachi_sustainable_2020, oecd_algorithmic_2023, harrington_developing_2018}.
%
%\subsubsection*{Traditional antitrust frameworks and algorithmic challenges}
%
%The regulatory literature reveals fundamental challenges in applying traditional antitrust frameworks to algorithmic collusion. Current competition law requires evidence of agreement or concerted practices, creating enforcement gaps when algorithms achieve collusive outcomes through autonomous learning. \textcite{calvano_artificial_2020} demonstrated that Q-learning algorithms consistently learn collusive strategies without communication, highlighting the inadequacy of intent-based legal frameworks.
%
%European regulatory approaches have emphasized transparency and auditing requirements through the Digital Markets Act and Digital Services Act. However, research suggests that transparency mandates may paradoxically facilitate coordination by making pricing strategies more visible to competitors. This regulatory challenge is particularly acute for LLM agents, whose decision-making processes are largely opaque and whose behavior can be influenced by seemingly innocuous modifications to prompts \parencite{lin_strategic_2025, fish_algorithmic_2025}.
%
%\subsubsection*{Detection methodologies and enforcement innovations}
%
%Emerging detection methodologies focus on algorithmic auditing and pattern recognition rather than traditional communication-based evidence. Research proposes \en{retraining tests} where unilateral algorithm changes can reveal collusive behavior patterns in observational data. Machine learning approaches have demonstrated success in identifying collusive patterns in public procurement with high accuracy across datasets \parencite{wallimann_machine_2023, digital_regulation_cooperation_forum_auditing_2022}.
%
%The regulatory challenge is particularly acute for LLM agents because their strategic capabilities emerge from training on human-generated text rather than explicit programming. \textcite[p.24]{fish_algorithmic_2025} found that \en{seemingly innocuous instructions in broad lay terms, can quickly and robustly arrive at supracompetitive price levels, to the detriment of consumers}, creating unprecedented compliance challenges for firms deploying these systems.
%
%\subsubsection*{Policy implications and intervention strategies}
%
%Regulatory approaches increasingly emphasize proactive intervention rather than reactive enforcement. However, balancing innovation incentives with consumer protection remains challenging, particularly for beneficial algorithmic applications \parencite{digital_regulation_cooperation_forum_auditing_2022}.
%
%Furthermore, the emergence of LLM agents creates policy needs because these systems can be rapidly deployed in strategic business roles and are widely accessible. Their autonomous collusion capabilities pose unique challenges for maintaining competitive markets, requiring new frameworks that can address the sophisticated strategic reasoning of AI systems while preserving beneficial applications.
%
%\subsection{Synthesis and research contributions}
%
%The convergence of theoretical advances in algorithmic collusion, empirical insights from real market coordination studies, and sophisticated LLM agent capabilities creates unprecedented opportunities for understanding how AI systems behave under actual competitive conditions, while simultaneously revealing critical gaps in current research that this research addresses. This synthesis reveals three interconnected contributions that collectively advance both theoretical understanding and practical applications of algorithmic collusion research. The integration encompasses bridging previously separate theoretical and empirical research streams to create comprehensive frameworks for analysis, developing methodological innovations that enable rigorous testing of algorithmic behavior under realistic market conditions, and establishing policy-relevant insights that inform regulatory approaches to AI-driven strategic behavior across diverse market contexts.
%
%\subsubsection*{Bridging theoretical and empirical approaches}
%
%This literature review reveals a critical gap: while theoretical studies demonstrate the collusive capabilities of LLM agents and empirical studies document sophisticated coordination mechanisms in real markets, no research has combined these approaches to examine LLM agent behavior under actual market conditions. The proposed thesis addresses this gap by applying theoretical insights from \textcite{fish_algorithmic_2025} to the empirical context of \textcite{byrne_learning_2019}, investigating whether LLM agents reproduce realistic coordination patterns when exposed to actual gasoline market conditions.
%
%The gasoline market constitutes an ideal testing ground for several reasons. First, extensive empirical documentation of coordination mechanisms provides natural benchmarks for evaluating the behavior of LLM agents. Second, high-frequency price data and spatial competition dynamics create rich strategic environments for testing algorithmic coordination. Third, the combination of regulatory scrutiny and competitive pressure provides realistic constraints on strategic behavior.
%
%\subsubsection*{Methodological innovations and empirical opportunities}
%
%The synthesis of LLM capabilities with empirical market studies enables several methodological innovations. LLM agents can be exposed to actual price histories, market structures, and demand conditions to examine whether they discover and implement the exact coordination mechanisms documented in empirical studies. This approach enables testing whether algorithmic collusion findings from controlled laboratory settings can be extended to realistic market environments.
%
%Empirical validation opportunities include comparing LLM agent pricing patterns with documented coordination mechanisms, examining whether agents reproduce Edgeworth cycles and price leadership patterns, and testing how information asymmetries and market structure affect algorithmic coordination. The rich empirical foundation enables precise benchmarking of algorithmic behavior against human strategic interaction.
%
%\subsubsection*{Policy implications and regulatory insights}
%
%Understanding how these agents behave under realistic market conditions provides crucial insights for the design and enforcement of regulatory strategies. The combination of theoretical capabilities and empirical validation enables a more precise assessment of consumer welfare effects and competitive harm.
%
%The regulatory implications extend beyond gasoline markets to any industry where LLM agents might be deployed for strategic decision-making. The research provides a framework for evaluating algorithmic collusion risks in different market contexts and for designing interventions that preserve beneficial AI applications while preventing anticompetitive outcomes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our literature review synthesizes research across interconnected domains to establish the theoretical and empirical foundation for investigating how algorithmic collusion among LLM agents breaks down as market concentration decreases. Building on the \emph{Folk Theorem}'s predictions about collusion sustainability and recent advances in LLM-based economic agents, this review demonstrates how collusion theory can be enhanced through empirical testing of AI coordination mechanisms across varying market structures. While theoretical studies demonstrate the capacity of LLM agents for autonomous collusion in controlled settings, and empirical studies reveal sophisticated coordination mechanisms in real markets, research has not yet systematically examined how LLM agent coordination varies with the number of market participants---a gap this thesis addresses. Or as \textcite[p.24]{fish_algorithmic_2025} state:
\begin{displayquote}
    \en{[\dots] our economic environment is simple and does not capture many real-world complexities, and we focus on one fixed time horizon. We leave exploring these frontiers to future research.}
\end{displayquote}

Thus, our approach to increasing the size of market participants and their impact on one another also constitutes a further advancement of agentic research towards greater real-world complexity.

\subsection{\emph{Folk Theorem} and Collusion Sustainability Theory}

The theoretical understanding of collusion sustainability across different market structures has evolved from early demonstrations of repeated game equilibria to sophisticated analyses of coordination mechanisms under varying strategic environments. This evolution encompasses three critical phases that lay the groundwork for understanding how AI systems might maintain or lose the ability to coordinate as market participation increases. (1) The progression begins with seminal contributions that establish the mathematical conditions for collusion sustainability, (2) advances through analyses of optimal punishment mechanisms, and (3) culminates in recent extensions that directly address bounded rationality and computational constraints relevant to algorithmic agents.

\subsubsection*{Foundational Theoretical Framework}

The theoretical foundation for understanding collusion sustainability was established by \textcite{friedman_non-cooperative_1971} in his seminal analysis of infinitely repeated games. Friedman's \en{grim trigger} strategy demonstrated that collusive outcomes could be sustained through credible punishment threats, establishing the fundamental sustainability condition:

\begin{equation}
    \delta \geq \frac{\pi^{D} - \pi^{C}}{\pi^{D} - \pi^{N}}
\end{equation}

where $\delta$ represents the discount factor, $\pi^{D}$ represents profits from deviation, $\pi^{C}$ represents collusive profits, and $\pi^{N}$ represents punishment period profits. This condition reveals the central tension in collusion sustainability: as the gains from deviation increase relative to collusive profits, maintaining cooperation requires increasingly patient players.

The significance of this framework was substantially enhanced by \textcite{fudenberg_folk_1986}, who provided the definitive statement of the \emph{Folk Theorem} for repeated games with discounting. Their analysis demonstrated that any individually rational payoff vector can be supported as a subgame perfect equilibrium when players are sufficiently patient, with this result holding unconditionally for two-player games and extending to n-player games under a full-dimensionality condition on the feasible payoff set. While they identified potential discontinuities in degenerate cases, their work formally established that $\delta \rightarrow 1$ enables any feasible, individually rational outcome in the economically relevant scenarios. This result provides the theoretical backbone for understanding why collusion becomes more difficult as market structures change in ways that affect the discount factor requirements.

%\textcite{kandori_social_1992} extended the \emph{Folk Theorem} to community enforcement settings where agents change partners over time, demonstrating that cooperation can be sustained through social norms even when direct bilateral relationships are infrequent. Kandori's analysis revealed that community enforcement faces increasing informational challenges as group size grows: with minimal information processing, cooperation becomes impossible to sustain in large populations, while effective community enforcement requires increasingly sophisticated information transmission mechanisms such as reputation systems or membership labels. His work established that larger communities need more complex institutional arrangements to overcome the coordination problems inherent in punishing defectors when agents cannot directly observe all interactions, providing theoretical foundations for understanding how group size affects the feasibility and design of community-based cooperation mechanisms.

\subsubsection*{Market Structure and Participation Effects}

The relationship between market structure and the sustainability of collusion has been rigorously analyzed through extensions of the basic \emph{Folk Theorem} framework. When collusive profits must be divided among $n$ participants, the individual payoff from cooperation becomes $\pi^C = \frac{\pi^M}{n}$, where $\pi^M$ represents monopoly profits. This relationship creates a fundamental mathematical tension: as $n$ increases, $\pi^C$ decreases while the coordination costs and complexity of punishment mechanisms increase, requiring the discount factor to approach unity for sustainability.

For instance, recent theoretical work has provided foundations for understanding algorithmic collusion through learning dynamics. \textcite{cartea_algorithmic_2022} prove a \emph{Folk Theorem} for bounded rationality learning in repeated potential games, demonstrating that algorithms using state-dependent smooth fictitious play can learn to sustain virtually any feasible and individually rational payoff profile, including collusive outcomes. Their analysis shows that learning algorithms with bounded memory strategies can converge to subgame perfect equilibria that embody reward-punishment mechanisms necessary for sustained cooperation. Importantly, their results require sufficient patience (high discount factors), adequate memory length, and appropriate perturbation parameters, providing theoretical validation for competition authorities' concerns about algorithmic collusion while highlighting the specific conditions under which such coordination can emerge through learning without explicit communication.

%\subsection{Market Concentration and Collusion: Empirical Evidence}
%
%Empirical research provides some validation of the \emph{Folk Theorem}'s predictions regarding the relationship between market structure and the sustainability of collusion. This literature encompasses historical analyses of actual cartels, experimental studies involving human participants, and recent field evidence on the adoption of algorithmic pricing.
%
%\subsubsection*{Historical Evidence and Cartel Stability Analysis}
%
%\textcite{porter_study_1983} provides landmark empirical evidence through his analysis of the Joint Executive Committee railroad cartel from 1880-1886. Using switching regression models to identify periods of collusive versus competitive behavior, Porter demonstrates that the cartel experienced periodic breakdowns that align with Green and Porter's theoretical predictions about enforcement under imperfect information. The breakdown episodes occurred when firms could not distinguish between low prices caused by cheating versus adverse demand shocks, leading to punishment phases that were actually equilibrium outcomes rather than coordination failures. Porter's methodology established a template for empirical collusion analysis, and the detailed railroad data enabled precise identification of switching between cooperative and non-cooperative regimes over time.
%
%\textcite{levenstein_what_2006} synthesize evidence across multiple cartel episodes and industries, conducting a comprehensive meta-analysis of factors affecting cartel success. Their survey encompasses documented cartel cases spanning different countries, time periods, and market structures. The analysis reveals mixed empirical evidence regarding the relationship between the number of firms and cartel sustainability, suggesting a more nuanced relationship than simple theory suggests. While many successful cartels do involve concentrated industries, the empirical evidence on the relationship between industry concentration and cartel stability is mixed. The authors find that organizational responses, such as industry associations, can overcome the challenges posed in forming a cartel in an unconcentrated industry. Cartels can, by increasing profitability, allow marginal firms to survive and thereby decrease concentration.

\subsubsection*{Experimental Evidence on Group Size Effects}

The experimental literature provides controlled evidence on how group size affects coordination outcomes. \textcite{huck_two_2004} conduct systematic experimental oligopoly studies comparing coordination success across 2, 3, 4, and 5 participants in repeated Cournot games. Their results establish threshold effects: duopolies achieve \en{some collusion} above competitive levels, triopolies \en{produce at Nash levels} with \en{no successful coordination above Nash}, and markets with four or more participants are \en{never collusive and often exceed Nash output levels} \parencite[p. 435]{huck_two_2004}. The experimental design enables precise control of payoff structures, information conditions, and strategic environments, confirming that group size effects operate independently of other market characteristics.

\textcite{fonseca_explicit_2012} extend this analysis by comparing explicit versus tacit collusion across different group sizes ($n=2,4,6,8$). Their experiments demonstrate that while communication facilitates coordination and leads to higher profits for all group sizes, the gains from communication follow an inverse U-shaped pattern, with medium-sized industries ($n=4$) achieving the largest additional benefits from explicit coordination. The communication treatments reveal that larger groups face increasing coordination challenges, as firms struggle to establish and maintain collusive agreements despite having the ability to communicate explicitly. This finding suggests that coordination problems in larger groups arise from fundamental challenges in coordinating pricing strategies rather than merely from communication constraints.

\textcite{engel_how_2007} provides a comprehensive meta-analysis of more than 100 experimental papers on oligopoly, systematically documenting how collusion varies with market structure parameters across more than 500 different parameter constellations. Engel's analysis reveals that collusion generally decreases with market size. However, the relationship is complex, with the data supporting the experimentalist view that \en{two are few, and four are many} rather than showing a perfectly systematic decline. The meta-analytic approach enables identification of robust patterns that transcend specific experimental designs, confirming that group size effects represent essential features of strategic interaction rather than artifacts of particular laboratory conditions.

%\subsubsection*{Strategic Mechanisms and Coordination Failure}
%
%\textcite{athey_optimal_2001} provide a theoretical analysis of optimal collusion with private information in a two-firm infinitely repeated Bertrand game. Their model examines how firms with privately observed cost shocks can achieve collusive outcomes through market-share favors and communication mechanisms. The paper focuses on characterizing optimal collusive conduct when firms have private information about their costs and face restrictions on side-payments, demonstrating that first-best profits can be achieved when firms are sufficiently patient. The theoretical framework shows how market-share favors can substitute for monetary transfers in providing incentives for truthful revelation of private cost information. The analysis reveals that communication can both facilitate coordination by enabling state-contingent market allocation and potentially harm collusion by exacerbating temptations to deviate when firms know their opponents' exact circumstances.

\subsection{Algorithmic Collusion: From Q-Learning to Advanced AI}

The emergence of algorithmic pricing has introduced new dimensions to collusion analysis, as artificial intelligence systems demonstrate the capacity for autonomous coordination without explicit agreements. This research stream reveals both continuities and discontinuities with traditional collusion patterns, providing insights into how algorithmic agents might behave differently from human participants while still facing fundamental coordination constraints as market participation increases.

\subsubsection*{Foundational Research on Algorithmic Coordination}

\textcite{calvano_artificial_2020} provide the foundational demonstration that Q-learning algorithms consistently learn supracompetitive prices in repeated Bertrand competition without explicit instructions to coordinate. Using simulations of logit demand environments, they demonstrate that algorithms autonomously develop sophisticated collusive strategies featuring punishment schemes with finite retaliation phases followed by gradual returns to cooperation. About group size effects, the authors \parencite*[p. 3268]{calvano_artificial_2020} note: 

    \begin{quote}
        \en{The degree of collusion decreases as the number of competitors rises. However, substantial collusion continues to prevail when the active firms are three or four in number. The algorithms display a stubborn propensity to collude even when they are asymmetric, and when they operate in stochastic environments.}
    \end{quote}

The mechanisms underlying algorithmic collusion differ fundamentally from human coordination approaches. Where human collusion typically requires explicit communication or coordination mechanisms, Q-learning algorithms discover collusive strategies through trial-and-error processes that systematically explore the strategy space. However, this exploration does not guarantee discovery of Nash equilibria---rather, the algorithms learn strategies that approximate optimal responses to rivals' behaviors, with varying degrees of success depending on exploration parameters.

\textcite{calvano_artificial_2020} work established three critical insights: first, that artificial intelligence can independently discover and implement classical collusive strategies; second, that no explicit communication or agreement is required for algorithmic coordination; and third, that these outcomes emerge from standard profit-maximization objectives rather than programmed collusive intent.

\subsubsection*{Advanced Learning Mechanisms and Coordination Robustness}

\textcite{klein_autonomous_2021} contemporaneous framework comprising sequential pricing environments using the Maskin-Tirole model, demonstrates that Q-learning algorithms converge to collusive equilibria when price sets are limited, and to supra-competitive asymmetric cycles when price flexibility increases. This work established the robustness of algorithmic collusion across different market structures and timing assumptions.

Additionally, \textcite{calvano_algorithmic_2021} demonstrate that algorithmic collusion persists even under imperfect monitoring conditions, adapting the framework of \textcite{green_noncooperative_1984} to algorithmic environments. Their analysis reveals that algorithms develop punishment schemes triggered by the observation of low prices, featuring punishments of finite duration that are initially harsh and gradually decrease in severity. These punishment mechanisms mirror optimal strategies identified in the theoretical literature, but they emerge autonomously from algorithmic learning rather than being explicitly designed.

The robustness of algorithmic coordination under imperfect monitoring is particularly significant for understanding how participation affects stability. \textcite{calvano_algorithmic_2021} show that algorithms can maintain coordination when monitoring is noisy or incomplete, but effectiveness depends critically on the ability to distinguish between competitive responses and random shocks. As the number of participants increases, this distinction becomes increasingly complex, leading to more frequent mistaken punishments and reduced effectiveness of coordination, though substantial collusive profits persist even with four firms.

\textcite{asker_artificial_2022, asker_impact_2024} provide crucial insights into how algorithm design choices affect pricing outcomes in oligopolistic markets. Their comparison of synchronous versus asynchronous learning protocols reveals that seemingly technical implementation decisions have profound competitive implications. Perfect synchronous updating, where algorithms can calculate counterfactual profits from alternative prices, leads to competitive (Nash equilibrium) pricing when firms do not value future profits ($\beta = 0$). In contrast, asynchronous learning, where algorithms only observe profits from their actual price choices, consistently results in supra-competitive pricing significantly above Nash levels. The propensity for supra-competitive outcomes under asynchronous learning diminishes systematically as the number of firms increases, with markets containing five or more firms exhibiting a minimal tendency to price above competitive levels.

\subsubsection*{Distinguishing Genuine from Spurious Coordination}

\textcite{calvano_algorithmic_2023} investigate when algorithmic collusion can be considered genuine, in the sense of arising from stable strategic equilibria supported by reward-punishment schemes, versus when it is spurious, resulting from artifacts of specific learning dynamics such as exploration methods. They demonstrate that algorithmic design choices—particularly the mode and intensity of exploration—critically influence whether algorithms converge to genuinely collusive outcomes or merely fail to learn to compete effectively. Genuine collusion emerges when algorithms with memory and sufficient patience (i.e., a high discount factor) learn equilibrium strategies sustained by threats of punishment. In contrast, spurious collusion can arise under conditions such as optimistic initialization, even in settings where collusion is not theoretically sustainable.

\subsection{LLM Agents and Multi-Agent Strategic Behavior}

The emergence of LLM-based agents represents a paradigm shift from traditional algorithmic approaches to strategic interaction. Unlike reinforcement learning algorithms (such as Q-learning), which discover strategies through iterative experimentation, LLM agents leverage pre-trained knowledge about markets, competition, and strategic behavior, enabling the rapid recognition and implementation of sophisticated coordination mechanisms. This fundamental difference in learning approach creates both opportunities for enhanced coordination and potential vulnerabilities to coordination breakdown as strategic complexity increases.

\subsubsection*{LLM Strategic Capabilities and Coordination Mechanisms}

\textcite{fish_algorithmic_2025} provide the first comprehensive analysis of LLM pricing agents, revealing three critical findings that distinguish LLM coordination from traditional algorithmic approaches. First, LLMs demonstrate natural proficiency in pricing tasks, achieving near-optimal pricing in monopoly settings within 100 periods and capturing 99\% of optimal profit in 96\% of periods. This rapid convergence contrasts sharply with Q-learning algorithms that require extensive exploration phases to identify profitable strategies.

Second, LLM-based pricing agents quickly and autonomously reach supracompetitive prices in oligopoly settings without explicit instructions to coordinate. The coordination emerges through what \textcite{fish_algorithmic_2025} identify as price-war avoidance mechanisms, where agents recognize the long-term costs of competitive interactions and adjust strategies accordingly. This mechanism operates through sophisticated reasoning about opponent responses rather than mechanical trial-and-error learning, enabling more rapid coordination but potentially creating different vulnerabilities as market complexity increases.

Third, and most significantly for understanding coordination breakdown, LLM agents exhibit extreme sensitivity to prompt variations, with seemingly innocuous instruction changes having a substantial influence on coordination outcomes. \textcite{fish_algorithmic_2025} demonstrate that prompts emphasizing long-run profit maximization consistently produce higher prices and profits than prompts mentioning competitive strategies or quantity considerations. This sensitivity suggests that LLM coordination depends on maintaining consistent strategic frameworks across participants---a requirement that might become increasingly difficult to satisfy as participation expands.

\subsubsection*{Multi-Commodity Competition and Market Division}

\textcite{lin_strategic_2025} provide compelling evidence of LLM agents' capacity for strategic coordination through their analysis of multi-commodity Cournot competition. Their experiments reveal that LLM agents effectively monopolize specific commodities by dynamically adjusting pricing and resource allocation strategies without explicit coordination instructions. Most remarkably, agents demonstrate what the authors \parencite*[p. 6]{lin_strategic_2025} term \en{emergent collusive dynamics} where they effectively divide sales territories and tacitly coordinate to discourage competition.

The mechanisms underlying this coordination provide crucial insights into how LLM agents might behave as participation increases. \textcite[p. 6]{lin_strategic_2025} observe that \en{despite the absence of any explicit communication channel, agents never re-enter a market once they have exited}, demonstrating implicit understanding of long-term strategic consequences. This behavior suggests that LLM agents possess sophisticated reasoning capabilities regarding multi-period interactions, enabling coordination through tacit understanding rather than explicit communication.

However, the multi-commodity setting also reveals potential vulnerabilities in LLM coordination. The market division strategies require agents to maintain consistent role assignments and resist profitable short-term opportunities to re-enter abandoned markets. \textcite[p. 8]{lin_strategic_2025} note that this behavior is \en{particularly surprising given the absence of explicit coordination channels and the potential short-term profits available from market re-entry}.

\subsubsection*{Systematic Evaluation of Coordination Capabilities}

\textcite{agashe_llm-coordination_2025} present a comprehensive evaluation of LLM coordination abilities in pure cooperation scenarios using the LLM-Coordination benchmark. This framework evaluates LLMs across Agentic Coordination and CoordinationQA tasks to test multi-agent reasoning in diverse strategic games. Their results show that LLM agents perform well when coordination hinges on environmental cues and explicit signals, but encounter substantial difficulties in tasks that require belief modeling and Theory of Mind (ToM) reasoning. These limitations become more pronounced as coordination complexity increases with the addition of more participants.

The evaluation highlights three successful mechanisms: (1) environmental coordination via shared observations, (2) explicit signal-based communication, and (3) convention-based behavior. However, belief-based coordination—where agents must reason about partners' hidden mental states and intentions—remains a core limitation. As the number of agents grows, successful coordination increasingly requires robust ToM and joint planning capabilities, areas where current LLM agents exhibit systematic weaknesses.

\textcite{piatti_cooperate_2025} investigate the limitations of LLM coordination in common pool resource dilemmas using the GOVSIM simulation platform. Evaluating fifteen LLMs across multiple runs and three resource-sharing scenarios, they find that only the most powerful models achieve sustainable cooperation, with the highest observed survival rate below 54\%. Their analysis reveals that communication is critical for sustainable behavior, and coordination fails systematically in the absence of communication or sufficient belief modeling about others' actions.

These findings suggest that while some LLM agents can engage in limited cooperative reasoning, they face significant constraints in sustaining cooperation under complex, multi-agent dynamics. The interplay between enhanced language-based reasoning and limitations in long-term planning leads to brittle cooperation patterns that often break down without structured interaction mechanisms.


% \subsubsection*{Methodological innovations in agent-based modeling}
% 
% The integration of LLMs into economic simulation represents a fundamental advancement in computational economics. \textcite{li_econagent_2024, li_large_2023} demonstrated LLM agents' superior performance in macroeconomic simulation through their EconAgent framework, which successfully reproduced key economic phenomena, including the Phillips curve and Okun's law---relationships that traditional rule-based and reinforcement learning approaches failed to capture accurately.
% 
% The methodological innovation stems from the multi-module architecture of LLM agents, which combines perception, memory, reflection, and action capabilities. This enables agents to process complex economic information, maintain decision histories, adapt strategies based on experience, and generate realistic economic choices---capabilities that mirror human economic decision-making more closely than traditional algorithmic approaches.
% 
% \textcite{gao_large_2024} provide a comprehensive survey of LLM-empowered agent-based modeling applications across cyber, physical, social, and hybrid domains. Their review demonstrates the versatility of LLM agents in simulating complex systems. It highlights the potential for these approaches to capture sophisticated social dynamics underlying economic decision-making, including information propagation and strategic interactions relevant to coordination and collusion.

\subsubsection*{Strategic behavior and collusion emergence}

Recent research reveals that LLM agents can develop strategic behaviors. \textcite[p.1]{lin_strategic_2025} found that LLM agents can:
    \begin{displayquote}
        \en{effectively monopolize specific commodities by dynamically adjusting their pricing and resource allocation strategies, thereby maximizing profitability without direct human input or explicit collusion commands.}
    \end{displayquote}
In multi-commodity Cournot competition, the researchers observed that agents \en{effectively divide sales territories among each other and tacitly collude to discourage competition at the expense of the consumer} \parencite[p.2]{lin_strategic_2025}. Critically, \en{despite the absence of any explicit communication channel, agents never re-enter a market once they have exited} \parencite[p.6]{lin_strategic_2025} demonstrating \en{an implicit understanding of the long-term consequences} and suggesting \en{emergent collusive dynamics} \parencite[p.6]{lin_strategic_2025}.

The implications for collusion research are profound. \textcite[p.8]{lin_strategic_2025} argue that \en{LLMs possess the reasoning capability to reach cooperative equilibria} and that this behavior is \en{particularly surprising given the absence of explicit coordination channels and the potential short-term profits available from market re-entry}. While traditional algorithms learn collusive strategies through iterative market interactions, LLM agents appear to demonstrate an inherent strategic understanding that enables the rapid recognition and implementation of coordination mechanisms. This represents a qualitative difference in how algorithmic collusion might emerge and persist in real markets.

% \subsubsection*{Comparative advantages over traditional approaches}
% 
% Compared to rule-based agent-based models, LLM agents exhibit greater flexibility and adaptability to unforeseen circumstances. In comparison to reinforcement learning approaches, they demonstrate superior stability in macroeconomic indicators and better integration of domain-specific knowledge, without requiring extensive training periods.
% 
% Most significantly for collusion research, LLM agents demonstrate a more sophisticated understanding of strategic interaction contexts. Traditional Q-learning algorithms discover collusive strategies through mechanical trial-and-error processes. At the same time, LLM agents appear to understand the strategic logic underlying coordination, enabling them to adapt collusive strategy to new market conditions and regulatory environments.

\subsubsection*{Empirical Evidence from Real Markets}

\textcite{assad_algorithmic_2024} provide crucial empirical validation of algorithmic coordination effects through their analysis of German gasoline markets. Using structural break analysis to identify algorithmic pricing adoption periods, they demonstrate that algorithm deployment increased price margins by 15\% in non-monopoly markets, with even larger effects (36\% increases).

The empirical design enables the identification of participation effects by comparing coordination outcomes across different market structures. Markets with only partial algorithmic adoption showed no significant margin changes, suggesting that coordination effects emerge only when all competitors use algorithmic pricing---a finding that aligns with theoretical predictions about coordination requirements.

\subsection{Regulatory challenges and transparency effects}

The emergence of algorithmic collusion poses unprecedented challenges for regulatory frameworks designed around traditional models of strategic coordination, necessitating fundamental reconsiderations of antitrust enforcement and competition policy in the digital economy. These challenges manifest across three interconnected dimensions that collectively reveal the inadequacy of existing regulatory approaches and the urgent need for innovative enforcement strategies. The regulatory landscape encompasses traditional antitrust frameworks struggling to address autonomous algorithmic coordination, emerging detection methodologies that leverage technological advances to identify collusive patterns, and evolving policy approaches that seek to balance innovation incentives with consumer protection in algorithmic markets \parencite{ezrachi_sustainable_2020, oecd_algorithmic_2023, harrington_developing_2018}.

\subsubsection*{Traditional antitrust frameworks and algorithmic challenges}

The regulatory literature reveals fundamental challenges in applying traditional antitrust frameworks to algorithmic collusion. Current competition law requires evidence of agreement or concerted practices, creating enforcement gaps when algorithms achieve collusive outcomes through autonomous learning. \textcite{calvano_artificial_2020} demonstrated that Q-learning algorithms consistently learn collusive strategies without communication, highlighting the inadequacy of intent-based legal frameworks.

European regulatory approaches have emphasized transparency and auditing requirements through the Digital Markets Act and Digital Services Act. However, research suggests that transparency mandates may paradoxically facilitate coordination by making pricing strategies more visible to competitors. This regulatory challenge is particularly acute for LLM agents, whose decision-making processes are largely opaque and whose behavior can be influenced by seemingly innocuous modifications to prompts \parencite{lin_strategic_2025, fish_algorithmic_2025}.

% \subsubsection*{Detection methodologies and enforcement innovations}
% 
% Emerging detection methodologies focus on algorithmic auditing and pattern recognition rather than traditional communication-based evidence. Research proposes \en{retraining tests} where unilateral algorithm changes can reveal collusive behavior patterns in observational data. Machine learning approaches have demonstrated success in identifying collusive patterns in public procurement with high accuracy across datasets \parencite{wallimann_machine_2023, digital_regulation_cooperation_forum_auditing_2022}.
% 
% The regulatory challenge is particularly acute for LLM agents because their strategic capabilities emerge from training on human-generated text rather than explicit programming. \textcite[p.24]{fish_algorithmic_2025} found that \en{seemingly innocuous instructions in broad lay terms, can quickly and robustly arrive at supracompetitive price levels, to the detriment of consumers}, creating unprecedented compliance challenges for firms deploying these systems.

\subsubsection*{Policy implications and intervention strategies}

Regulatory approaches increasingly emphasize proactive intervention rather than reactive enforcement. However, balancing innovation incentives with consumer protection remains challenging, particularly for beneficial algorithmic applications \parencite{digital_regulation_cooperation_forum_auditing_2022}.

Furthermore, the emergence of LLM agents creates policy needs because these systems can be rapidly deployed in strategic business roles and are widely accessible. Their autonomous collusion capabilities pose unique challenges for maintaining competitive markets, requiring new frameworks that can address the sophisticated strategic reasoning of AI systems while preserving beneficial applications.

\subsection{Synthesis: Theoretical Predictions and Empirical Validation}

The convergence of \emph{Folk Theorem} predictions, empirical evidence on market concentration effects, and recent advances in LLM agent capabilities creates unprecedented opportunities for understanding how AI coordination emerges. Simultaneously, it might pose significant challenges to policymakers.

\subsubsection*{Research Gap and Contribution}

Despite this extensive theoretical foundation and empirical validation across multiple research domains, a gap remains in understanding how LLM agent coordination specifically varies with market participation. \textcite{fish_algorithmic_2025, lin_strategic_2025} provide evidence of LLM coordination capabilities in duopoly settings, demonstrating rapid autonomous coordination and sophisticated strategic reasoning. However, their analysis does not extend to markets with three, four, or more participants, leaving unresolved the fundamental question of whether LLM agents follow traditional \emph{Folk Theorem} patterns, other breakdown mechanisms, or whether they exhibit breakdown characteristics overall.

This gap is particularly significant given the unique characteristics of LLM agents identified in recent research. Unlike Q-learning algorithms that discover strategies through mechanical exploration, LLM agents leverage pre-trained strategic knowledge and demonstrate sophisticated reasoning about opponent behavior. These capabilities might enable coordination in circumstances where traditional algorithms fail, potentially shifting the traditional breakdown thresholds identified in human and algorithmic studies.

Alternatively, LLM agents face distinct computational and reasoning constraints that might create different vulnerabilities. The prompt sensitivity documented by \textcite{fish_algorithmic_2025} suggests that coordination depends on maintaining consistent strategic frameworks across participants---a requirement that becomes increasingly difficult with an increasing number of participants.

\subsubsection*{Theoretical Framework for Analysis}

The synthesis of theoretical and empirical literature establishes a clear framework for investigating the breakdown of LLM coordination. \emph{Folk Theorem} analysis predicts that coordination should become increasingly complex as the number of participants increases, with mathematical sustainability requiring $\delta \rightarrow 1$ as $n$ grows large. Theoretical evidence suggests specific breakdown thresholds around three to four participants, with transitions from coordinated to competitive outcomes.

For LLM agents, this framework generates specific testable predictions. If LLM coordination follows these patterns, we should observe coordination success in duopoly and triopoly settings with systematic breakdown as participation expands to more agents. If LLM agents' enhanced strategic reasoning capabilities enable superior coordination, breakdown thresholds might shift to larger participant numbers. If LLM agents face distinct cognitive or computational constraints, breakdown might occur at smaller participant numbers or exhibit different patterns than traditional approaches predict.

The research design, which tests these predictions across systematic variations in participant numbers, provides crucial evidence for understanding the boundaries of algorithmic coordination and the applicability of traditional collusion theory to AI-driven markets. These findings inform both theoretical understanding of AI strategic behavior and practical policy applications for antitrust enforcement in increasingly algorithmic markets.