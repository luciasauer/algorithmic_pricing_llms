\section{Discussion}\label{sec:dis}

This thesis provides the first systematic empirical test of Folk Theorem predictions in LLM-mediated markets, extending algorithmic collusion research beyond duopoly settings to examine the theoretical boundaries of AI coordination. Our findings demonstrate that LLM agents can achieve sustained supracompetitive outcomes across multiple market structures, but with coordination effectiveness declining systematically as predicted by economic theory.

\subsection{Core Findings and Literature Positioning}

Our central finding—a 3.7% price reduction per additional competitor with cumulative effects reaching 10.6% from duopoly to five-agent markets—provides the first quantitative validation of Folk Theorem predictions in LLM settings. This systematic breakdown pattern aligns with Calvano et al.'s (2020) observation that Q-learning algorithms maintained "substantial collusion" even "when the active firms are three or four in number" (p. 3268), but provides the missing quantification of breakdown trajectories they did not examine.

The experimental design enables clean identification of group size effects by holding constant all other market characteristics—demand structure, cost parameters, and agent specifications—while varying only the number of competing agents. This controlled variation extends beyond observational studies like Assad et al. (2024), whose analysis of German gasoline markets documented significant coordination effects (15% margin increases in non-monopoly markets) but could not isolate market structure effects from other confounding factors.

The systematic coordination breakdown contradicts concerns about AI systems potentially transcending traditional economic constraints. Instead, LLM agents appear subject to the same fundamental coordination challenges that constrain both human and traditional algorithmic coordination, albeit with notably higher baseline coordination capabilities than documented in prior Q-learning studies.

\subsection{Theoretical Implications and Coordination Mechanisms}

The observed "converge-and-persist" coordination pattern reveals that LLM agents coordinate through fundamentally different mechanisms than traditional reinforcement learning algorithms. While Calvano et al. (2020, 2021) documented Q-learning algorithms discovering collusive strategies through extended trial-and-error exploration, often requiring hundreds of periods to establish stable coordination, LLM agents rapidly converge to stable focal points and maintain them with minimal deviation. This behavioral difference reflects their pre-training on human-generated text about markets and strategic behavior.

However, the LLM coordination mechanism also creates distinctive vulnerabilities. The extreme price persistence (near-unit root behavior) suggests that coordination depends critically on maintaining stable strategic frameworks across participants—a requirement that becomes increasingly difficult as group size increases. This finding helps explain why coordination breakdown follows smooth patterns consistent with theoretical predictions rather than exhibiting sudden threshold effects.

The 18.8% price difference between prompt specifications (P1 vs P2) extends Fish et al.'s (2025) duopoly results to oligopoly settings, confirming that algorithmic coordination is highly sensitive to seemingly minor design choices. This prompt sensitivity operates independently of market structure effects, validating the robustness of Folk Theorem predictions across different algorithmic implementations while highlighting new regulatory concerns about unintentional coordination facilitation.

\subsection{Critical Limitations}

Several fundamental limitations constrain the interpretation and generalizability of our findings. Most critically, LLMs represent stochastic "black box" systems whose decision-making processes remain largely opaque. While our agents provide textual explanations for their pricing decisions, these explanations may reflect post-hoc rationalization rather than genuine strategic reasoning.

**Sample size constraints** represent a significant methodological limitation. Our experimental design, while sufficient for detecting major coordination effects, relies on relatively small sample sizes per treatment condition. The computational costs and API rate limits associated with LLM experimentation restrict the scale of data collection compared to traditional algorithmic studies, affecting both the precision of our estimates and our ability to detect smaller coordination effects.

**Model access limitations** constrain the generalizability of our findings across different AI architectures. Due to resource constraints and API availability, our analysis focuses primarily on open-source models (Mistral-Large-2411) rather than state-of-the-art proprietary systems like GPT-4o or Claude. Our attempts to replicate Fish et al.'s (2025) core findings using smaller, more accessible models were only partially successful, highlighting the sensitivity of LLM coordination to specific model architectures and raising important questions about robustness across different technological platforms.

External validity concerns arise from the synthetic nature of our experimental environment. Real markets exhibit complexities—asymmetric information, heterogeneous products, regulatory oversight, demand uncertainty—that could fundamentally alter coordination dynamics in practice.

\subsection{Policy Implications}

Our findings have important implications for competition policy in AI-mediated markets. The systematic coordination breakdown as market concentration decreases provides quantitative guidance for merger analysis, with the 3.7% per-competitor effect offering a concrete benchmark for assessing competitive effects in markets where algorithmic pricing is prevalent.

These experimental findings complement the empirical evidence from Assad et al. (2024), whose finding that coordination effects emerged only when all competitors adopted algorithmic pricing aligns with our experimental evidence that coordination requires stable strategic frameworks across participants—frameworks that become harder to maintain as participant numbers increase.

However, the demonstrated coordination capabilities—even in five-agent markets, prices remained substantially above competitive levels—highlight ongoing risks from algorithmic coordination. The accessibility of coordination-capable models, combined with their rapid deployment potential, suggests that algorithmic collusion threats may be more widespread than previously recognized.

The prompt sensitivity results reveal new dimensions of regulatory concern not captured in traditional antitrust frameworks. The substantial price differences arising from seemingly innocuous prompt modifications suggest that algorithmic coordination can emerge from design choices that firms might not recognize as strategically significant, creating novel compliance challenges for firms deploying LLM-based pricing systems.

\subsection{Future Research Directions}

**Price shock analysis** represents perhaps the most immediate and policy-relevant extension of this research. Testing how LLM coordination patterns respond to external market disruptions—cost shocks, demand shifts, or regulatory interventions—would provide crucial insights into the robustness of algorithmic collusion and inform regulatory strategies for market intervention. Unlike the stable environments examined here, real markets face constant perturbations that test coordination resilience in ways our controlled experiments cannot capture.

Additional research priorities include systematic analysis across state-of-the-art proprietary models (GPT-4o, Claude, Gemini) to determine whether coordination capabilities scale with model sophistication, examination of heterogeneous environments where algorithms compete against human decision-makers, and development of detection strategies for competition authorities. The methodological framework established here provides a foundation for such extensions while demonstrating that meaningful coordination research can be conducted using accessible models rather than resource-intensive proprietary systems.
