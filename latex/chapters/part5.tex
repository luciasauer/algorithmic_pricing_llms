\section{Discussion}\label{sec:dis}

This thesis provides the first systematic empirical test of \emph{Folk Theorem} logic in LLM-mediated markets, extending algorithmic collusion research beyond duopoly settings to examine the theoretical boundaries of AI coordination. Our findings suggest that LLM agents can achieve sustained supracompetitive outcomes across multiple market structures, but with coordination effectiveness declining systematically as predicted by economic theory.

\subsubsection*{Core Findings and Literature Positioning}

Our central finding—a 3.7\% price reduction per additional competitor with cumulative effects reaching 10.6\% from duopoly to five-agent markets—provides the first quantitative validation of \emph{Folk Theorem} logic in LLM settings. This systematic breakdown pattern aligns with \textcite[p. 3268]{calvano_artificial_2020} observation that Q-learning algorithms maintained \en{substantial collusion} even \en{when the active firms are three or four in number}, but provides the missing quantification of breakdown trajectories they did not examine.

However, several alternative mechanisms could explain our findings beyond the Folk Theorem logic. First, computational constraints may limit the ability of LLMs to track multiple competitors. Second, the complexity of prompts may increase with group size, affecting performance rather than strategic incentives. Third, coordination might reflect pattern matching from training data rather than genuine strategic reasoning.

\subsubsection*{Theoretical Implications and Coordination Mechanisms}

The observed \enquote{converge-and-persist} coordination pattern reveals that LLM agents coordinate through fundamentally different mechanisms than traditional reinforcement learning algorithms. While \textcite{calvano_artificial_2020,calvano_algorithmic_2021} documented Q-learning algorithms discovering collusive strategies through extended trial-and-error exploration, often requiring hundreds of periods to establish stable coordination, LLM agents rapidly converge to stable focal points and maintain them with minimal deviation. This behavioral difference reflects their pre-training on human-generated text about markets and strategic behavior.

However, the LLM coordination mechanism also creates distinctive vulnerabilities. The extreme price persistence (near-unit root behavior) suggests that coordination depends critically on maintaining stable strategic frameworks across participants—a requirement that becomes increasingly difficult as group size increases. This finding helps explain why coordination breakdown follows smooth patterns consistent with theoretical predictions rather than exhibiting sudden threshold effects.

The 18.8\% price difference between prompt specifications (P1 vs. P2) extends \textcite{fish_algorithmic_2025} duopoly results to oligopoly settings, confirming that algorithmic coordination is highly sensitive to seemingly minor design choices. This prompt sensitivity operates independently of market structure effects, validating the robustness of \emph{Folk Theorem} logic across different algorithmic implementations while highlighting new regulatory concerns about unintentional coordination facilitation.

\subsubsection*{Critical Limitations}

Several fundamental limitations constrain the interpretation and generalizability of our findings. Most critically, LLMs represent stochastic \enquote{black box} systems whose decision-making processes remain largely opaque. While our agents provide textual explanations for their pricing decisions, these explanations may reflect post-hoc rationalization rather than genuine strategic reasoning.

Sample size constraints represent a significant methodological limitation. Our experimental design, while sufficient for detecting major coordination effects, relies on relatively small sample sizes per treatment condition. The computational costs and API rate limits associated with LLM experimentation restrict the scale of data collection compared to traditional algorithmic studies, affecting both the precision of our estimates and our ability to detect smaller coordination effects.

Model access limitations constrain the generalizability of our findings across different AI architectures. Due to resource constraints and API availability, our analysis focuses primarily on open-source models (Mistral-Large-2411) rather than state-of-the-art proprietary systems like GPT-4o, Gemini, or Claude. Our attempts to replicate the core findings of \textcite{fish_algorithmic_2025} using smaller, more accessible models were only partially successful, highlighting the sensitivity of LLM coordination to specific model architectures and raising important questions about robustness across different technological platforms.

External validity concerns arise from the synthetic nature of our experimental environment. Real markets exhibit complexities—asymmetric information, heterogeneous products, regulatory oversight, and demand uncertainty---that could fundamentally alter coordination dynamics in practice.

\subsubsection*{Policy Implications}

Our findings have important implications for competition policy in AI-mediated markets. The systematic coordination breakdown as market concentration decreases provides quantitative guidance for merger analysis, with the 3.7\% per-competitor effect offering a concrete benchmark for assessing competitive effects in markets where algorithmic pricing is prevalent. These experimental findings complement the empirical evidence from \textcite{assad_algorithmic_2024}, who found that coordination effects emerged only when all competitors adopted algorithmic pricing. This finding aligns with our experimental evidence that coordination requires stable strategic frameworks across participants—frameworks that become harder to maintain as participant numbers increase.

However, the demonstrated coordination capabilities---even in five-agent markets— highlight ongoing risks from algorithmic coordination. The accessibility of coordination-capable models, combined with their rapid deployment potential, suggests that algorithmic collusion threats may be more widespread than previously recognized. The prompt sensitivity results reveal new dimensions of regulatory concern not captured in traditional antitrust frameworks. The substantial price differences arising from seemingly innocuous prompt modifications suggest that algorithmic coordination can emerge from design choices that firms might not recognize as strategically significant, creating novel compliance challenges for firms deploying LLM-based pricing systems.

\subsubsection*{Future Research Directions}

Price shock analysis represents perhaps the most immediate and policy-relevant extension of this research. Testing how LLM coordination patterns respond to external market disruptions---cost shocks, demand shifts, entries, exits, asymmetries, or regulatory interventions---would provide crucial insights into the robustness of algorithmic collusion and inform regulatory strategies for market intervention. Unlike the stable environments examined here, real markets face constant perturbations that test coordination resilience in ways our controlled experiments cannot capture.

Additional research priorities include systematic analysis across state-of-the-art proprietary models (GPT-4o, Claude, Gemini) to determine whether coordination capabilities scale with model sophistication, examination of heterogeneous environments where algorithms compete against human decision-makers, and development of detection strategies for competition authorities. The methodological framework established here provides a foundation for such extensions, demonstrating that meaningful coordination research can be conducted using accessible models rather than resource-intensive, proprietary systems.
